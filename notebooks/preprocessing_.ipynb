{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9694a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbc4fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42 \n",
    "# Python RNG \n",
    "random.seed(SEED) \n",
    "# NumPy RNG \n",
    "np.random.seed(SEED) \n",
    "# Optional: full determinism for sklearn parallel algorithms \n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED) \n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" \n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4387608",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40b5cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usuwanie i wypełnianie pustych danych \n",
    "\n",
    "missing_data = (df.isnull().sum()/len(df)) *100\n",
    "missing_data = missing_data[missing_data>0].sort_values(ascending = False).reset_index()\n",
    "missing_data.columns = [\"Cecha\",\"Procent\"]\n",
    "\n",
    "\n",
    "# do modyfikacji w zależności od ostatecznej potrzeby (jeszcze idk jakie będzią ostatecznie)\n",
    "# w %\n",
    "col_cutoff_treshold = 48\n",
    "col_trim_treshhold = 2\n",
    "\n",
    "\n",
    "cols_to_drop  = missing_data[missing_data['Procent'] > col_cutoff_treshold]['Cecha'].tolist()\n",
    "cols_to_trim = missing_data[missing_data['Procent'] < col_trim_treshhold]['Cecha'].tolist()\n",
    "\n",
    "df.drop(columns=cols_to_drop,inplace=True)\n",
    "df.dropna(subset=cols_to_trim,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6654be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_treshold = 0.90\n",
    "# te zmienne wprowadzały szum wcześniej ale jak dojdę do ogarniania feature engineering to coś z nimi zrobię obiecuje\n",
    "cols_to_drop  = [col for col in df.select_dtypes(include='object').columns if df[col].nunique()/len(df) > unique_treshold or df[col].nunique() == 1 ]\n",
    "df.drop(columns=['model','model_version','body_color_original'], inplace=True)\n",
    "\n",
    "df.drop(columns=cols_to_drop,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e3c9b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'price'\n",
    "\n",
    "# podział kolumn ze względu na typ\n",
    "numeric_cols = df.select_dtypes(include=[\"float\",\"int\"]).columns.tolist()\n",
    "\n",
    "bool_cols = df.select_dtypes(include=[\"bool\"]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "\n",
    "#dopiero w tym miejscu żeby na wykresie było widać\n",
    "numeric_cols.remove(target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d60a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_cols(data,numeric_cols,categorical_cols,stats):\n",
    "    for col in numeric_cols:\n",
    "        if col == 'gears' or col == 'nr_prev_owners':\n",
    "            data[col] = data[col].fillna(0)\n",
    "        else :\n",
    "            data[col] = data[col].fillna(stats[col])\n",
    "    for col,_ in categorical_cols:\n",
    "        data[col] = data[col].fillna(stats[col])\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess(data,numeric_cols,categorical_cols,scaler,stats):\n",
    "    data = fill_cols(data,numeric_cols,categorical_cols,stats)\n",
    "    data[numeric_cols] = scaler.transform(data[numeric_cols])\n",
    "    for col,vals in categorical_cols:\n",
    "        data[col] = pd.Categorical(data[col], categories=vals)\n",
    "    data = pd.get_dummies(data, drop_first=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d381eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seeded:\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        # Case 1: estimator is a class (e.g., RandomForestRegressor)\n",
    "        if hasattr(self.estimator, \"get_params\"):\n",
    "            # Instantiate a temporary object to inspect parameters\n",
    "            params = self.estimator().get_params()\n",
    "            if \"random_state\" in params and \"random_state\" not in kwargs:\n",
    "                kwargs[\"random_state\"] = SEED\n",
    "            return self.estimator(*args, **kwargs)\n",
    "\n",
    "        # Case 2: estimator is a function (e.g., train_test_split)\n",
    "        if hasattr(self.estimator, \"__code__\"):\n",
    "            if \"random_state\" in self.estimator.__code__.co_varnames and \"random_state\" not in kwargs:\n",
    "                kwargs[\"random_state\"] = SEED\n",
    "            return self.estimator(*args, **kwargs)\n",
    "\n",
    "        # Fallback\n",
    "        return self.estimator(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2546c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(target_col, axis=1), df[target_col]\n",
    "\n",
    "TTS = Seeded(train_test_split)\n",
    "X_train, X_test, y_train, y_test = TTS(X, y, test_size=0.2)\n",
    "X_subtest, X_valid, y_subtest, y_valid = TTS(X_test, y_test, test_size=0.5)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[numeric_cols])\n",
    "\n",
    "categorical_cols_with_vals = [ (col,[val for val in X_train[col].unique().tolist() if pd.notna(val)] ) for col in categorical_cols]\n",
    "\n",
    "# to robię by uniknąć data leakage (pewnie poprawię potem by ładniej wyglądało)\n",
    "stats = {col: X_train[col].median() for col in numeric_cols}\n",
    "stats.update({col: X_train[col].mode()[0] for col in categorical_cols})\n",
    "\n",
    "# tutaj gotowe dane do karmienia modelu\n",
    "X_train_preprocessed = preprocess(X_train,numeric_cols,categorical_cols_with_vals,scaler,stats)\n",
    "X_test_preprocessed = preprocess(X_test,numeric_cols,categorical_cols_with_vals,scaler,stats)\n",
    "X_subtest_preprocessed = preprocess(X_subtest,numeric_cols,categorical_cols_with_vals,scaler,stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20705b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7293326026353828\n"
     ]
    }
   ],
   "source": [
    "baseline = np.ones(len(y))*np.average(y)\n",
    "mse_baseline = metrics.mean_squared_error(y, baseline)\n",
    "\n",
    "clf = linear_model.LinearRegression()\n",
    "clf.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_preprocessed)\n",
    "mse_st = metrics.mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(mse_baseline / mse_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743d1c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear (double split): MSE walidacja = 3714596510.2884\n",
      "Ridge: MSE walidacja = 3732292913.2306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\magda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.334e+14, tolerance: 8.987e+10\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso: MSE walidacja = 3714604547.3699\n",
      "kNN: MSE walidacja = 5418547384.7756\n",
      "ElasticNet: MSE walidacja = 8786372685.9591\n",
      "RandomForestRegressor: MSE walidacja = 3646416435.8114\n",
      "Najlepszy model: RandomForestRegressor\n",
      "1.0426585540942201\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Linear (double split)\": linear_model.LinearRegression(),\n",
    "    \"Ridge\": Seeded(linear_model.Ridge)(alpha=0.1),\n",
    "    \"Lasso\": Seeded(linear_model.Lasso)(alpha=0.01),\n",
    "    \"kNN\": KNeighborsRegressor(n_neighbors=50, weights=\"distance\"),\n",
    "    \"ElasticNet\": Seeded(linear_model.ElasticNet)(alpha=0.1, l1_ratio=0.5),\n",
    "    \"RandomForestRegressor\": Seeded(RandomForestRegressor)(n_estimators=100, max_depth=20)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_preprocessed, y_train)\n",
    "    y_val_pred = model.predict(X_subtest_preprocessed)\n",
    "    mse_val_best = metrics.mean_squared_error(y_subtest, y_val_pred)\n",
    "    results[name] = mse_val_best\n",
    "    print(f\"{name}: MSE walidacja = {mse_val_best:.4f}\")\n",
    "\n",
    "best_model_name = min(results, key=results.get)\n",
    "print(f\"Najlepszy model: {best_model_name}\")\n",
    "\n",
    "y_pred = models[best_model_name].predict(X_test_preprocessed)\n",
    "mse_val_best = metrics.mean_squared_error(y_test, y_pred)\n",
    "print(mse_st / mse_val_best)\n",
    "\n",
    "rmse = np.sqrt(mse_val_best)\n",
    "mae  = metrics.mean_absolute_error(y_test, y_pred)\n",
    "r2   = metrics.r2_score(y_test, y_pred)\n",
    "mape = metrics.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(\"\\n=== Ewaluacja najlepszego modelu (test) ===\")\n",
    "print(f\"MSE:   {mse_val_best:.2f}\")\n",
    "print(f\"RMSE:  {rmse:.2f}\")\n",
    "print(f\"MAE:   {mae:.2f}\")\n",
    "print(f\"R2:    {r2:.4f}\")\n",
    "print(f\"MAPE:  {mape*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5104344e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear (double split): MSE walidacja = 0.0800\n",
      "Ridge: MSE walidacja = 0.0801\n",
      "Lasso: MSE walidacja = 0.1005\n",
      "kNN: MSE walidacja = 0.0550\n",
      "ElasticNet: MSE walidacja = 0.1386\n",
      "RandomForestRegressor: MSE walidacja = 0.0336\n",
      "Najlepszy model (skala log.): RandomForestRegressor\n"
     ]
    }
   ],
   "source": [
    "### Log-ification of database\n",
    "\n",
    "results_log = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_preprocessed, np.log1p(y_train))\n",
    "    y_val_pred_log = model.predict(X_subtest_preprocessed)\n",
    "    y_val_pred = np.expm1(y_val_pred_log)\n",
    "    mse_val = metrics.mean_squared_error(y_subtest, y_val_pred)\n",
    "    results_log[name] = mse_val\n",
    "    print(f\"{name}: MSE walidacja = {mse_val:.4f}\")\n",
    "\n",
    "best_model = models[best_model_name]\n",
    "print(f\"Najlepszy model (skala log.): {best_model_name}\")\n",
    "best_model.fit(X_train_preprocessed, np.log1p(y_train))\n",
    "\n",
    "y_pred_log = best_model.predict(X_test_preprocessed)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "mse_log = metrics.mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE test:\", mse_val_best / mse_log)\n",
    "\n",
    "rmse = np.sqrt(mse_log)\n",
    "mae  = metrics.mean_absolute_error(y_test, y_pred)\n",
    "r2   = metrics.r2_score(y_test, y_pred)\n",
    "mape = metrics.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(\"\\n=== Ewaluacja najlepszego modelu (test) ===\")\n",
    "print(f\"MSE:   {mse_log:.2f}\")\n",
    "print(f\"RMSE:  {rmse:.2f}\")\n",
    "print(f\"MAE:   {mae:.2f}\")\n",
    "print(f\"R2:    {r2:.4f}\")\n",
    "print(f\"MAPE:  {mape*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0464d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 112227 entries, 0 to 118381\n",
      "Data columns (total 34 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   price                     112227 non-null  float64\n",
      " 1   price_tax_deductible      112227 non-null  bool   \n",
      " 2   price_negotiable          112227 non-null  bool   \n",
      " 3   make                      112227 non-null  object \n",
      " 4   mileage_km                112227 non-null  float64\n",
      " 5   nr_seats                  109296 non-null  float64\n",
      " 6   nr_doors                  112227 non-null  float64\n",
      " 7   body_color                101406 non-null  object \n",
      " 8   paint_type                88557 non-null   object \n",
      " 9   upholstery                87982 non-null   object \n",
      " 10  upholstery_color          82242 non-null   object \n",
      " 11  power_kw                  112227 non-null  float64\n",
      " 12  power_hp                  112227 non-null  float64\n",
      " 13  transmission              112227 non-null  object \n",
      " 14  gears                     72686 non-null   float64\n",
      " 15  drive_train               87619 non-null   object \n",
      " 16  cylinders                 91406 non-null   float64\n",
      " 17  cylinders_volume_cc       102518 non-null  float64\n",
      " 18  weight_kg                 91752 non-null   float64\n",
      " 19  has_particle_filter       112227 non-null  bool   \n",
      " 20  fuel_category             112227 non-null  object \n",
      " 21  is_used                   112227 non-null  bool   \n",
      " 22  is_new                    112227 non-null  bool   \n",
      " 23  is_preregistered          112227 non-null  bool   \n",
      " 24  had_accident              112227 non-null  bool   \n",
      " 25  has_full_service_history  112227 non-null  bool   \n",
      " 26  non_smoking               112227 non-null  bool   \n",
      " 27  nr_prev_owners            62734 non-null   float64\n",
      " 28  is_rental                 112227 non-null  bool   \n",
      " 29  envir_standard            74735 non-null   object \n",
      " 30  offer_type                112227 non-null  object \n",
      " 31  country_code              112227 non-null  object \n",
      " 32  car_age                   112227 non-null  float64\n",
      " 33  price_log                 112227 non-null  float64\n",
      "dtypes: bool(10), float64(13), object(11)\n",
      "memory usage: 22.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (df.info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
