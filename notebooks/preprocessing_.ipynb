{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9694a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dbc4fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42 \n",
    "# Python RNG \n",
    "random.seed(SEED) \n",
    "# NumPy RNG \n",
    "np.random.seed(SEED) \n",
    "# Optional: full determinism for sklearn parallel algorithms \n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED) \n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" \n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4387608",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data_cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40b5cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usuwanie i wypełnianie pustych danych \n",
    "\n",
    "missing_data = (df.isnull().sum()/len(df)) *100\n",
    "missing_data = missing_data[missing_data>0].sort_values(ascending = False).reset_index()\n",
    "missing_data.columns = [\"Cecha\",\"Procent\"]\n",
    "\n",
    "\n",
    "# do modyfikacji w zależności od ostatecznej potrzeby (jeszcze idk jakie będzią ostatecznie)\n",
    "# w %\n",
    "col_cutoff_treshold = 48\n",
    "col_trim_treshhold = 2\n",
    "\n",
    "\n",
    "cols_to_drop  = missing_data[missing_data['Procent'] > col_cutoff_treshold]['Cecha'].tolist()\n",
    "cols_to_trim = missing_data[missing_data['Procent'] < col_trim_treshhold]['Cecha'].tolist()\n",
    "\n",
    "df.drop(columns=cols_to_drop,inplace=True)\n",
    "df.dropna(subset=cols_to_trim,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6654be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_treshold = 0.90\n",
    "# te zmienne wprowadzały szum wcześniej ale jak dojdę do ogarniania feature engineering to coś z nimi zrobię obiecuje\n",
    "cols_to_drop  = [col for col in df.select_dtypes(include='object').columns if df[col].nunique()/len(df) > unique_treshold or df[col].nunique() == 1 ]\n",
    "df.drop(columns=['model','model_version','body_color_original'], inplace=True)\n",
    "\n",
    "df.drop(columns=cols_to_drop,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e3c9b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'price'\n",
    "\n",
    "# podział kolumn ze względu na typ\n",
    "numeric_cols = df.select_dtypes(include=[\"float\",\"int\"]).columns.tolist()\n",
    "\n",
    "bool_cols = df.select_dtypes(include=[\"bool\"]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "\n",
    "#dopiero w tym miejscu żeby na wykresie było widać\n",
    "numeric_cols.remove(target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d60a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_cols(data,numeric_cols,categorical_cols,stats):\n",
    "    for col in numeric_cols:\n",
    "        if col == 'gears' or col == 'nr_prev_owners':\n",
    "            data[col] = data[col].fillna(0)\n",
    "        else :\n",
    "            data[col] = data[col].fillna(stats[col])\n",
    "    for col,_ in categorical_cols:\n",
    "        data[col] = data[col].fillna(stats[col])\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess(data,numeric_cols,categorical_cols,scaler,stats):\n",
    "    data = fill_cols(data,numeric_cols,categorical_cols,stats)\n",
    "    data[numeric_cols] = scaler.transform(data[numeric_cols])\n",
    "    for col,vals in categorical_cols:\n",
    "        data[col] = pd.Categorical(data[col], categories=vals)\n",
    "    data = pd.get_dummies(data, drop_first=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d381eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seeded:\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        # Case 1: estimator is a class (e.g., RandomForestRegressor)\n",
    "        if hasattr(self.estimator, \"get_params\"):\n",
    "            # Instantiate a temporary object to inspect parameters\n",
    "            params = self.estimator().get_params()\n",
    "            if \"random_state\" in params and \"random_state\" not in kwargs:\n",
    "                kwargs[\"random_state\"] = SEED\n",
    "            return self.estimator(*args, **kwargs)\n",
    "\n",
    "        # Case 2: estimator is a function (e.g., train_test_split)\n",
    "        if hasattr(self.estimator, \"__code__\"):\n",
    "            if \"random_state\" in self.estimator.__code__.co_varnames and \"random_state\" not in kwargs:\n",
    "                kwargs[\"random_state\"] = SEED\n",
    "            return self.estimator(*args, **kwargs)\n",
    "\n",
    "        # Fallback\n",
    "        return self.estimator(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2546c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(target_col, axis=1), df[target_col]\n",
    "\n",
    "TTS = Seeded(train_test_split)\n",
    "X_train, X_test, y_train, y_test = TTS(X, y, test_size=0.2)\n",
    "X_subtest, X_valid, y_subtest, y_valid = TTS(X_test, y_test, test_size=0.5)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[numeric_cols])\n",
    "\n",
    "categorical_cols_with_vals = [ (col,[val for val in X_train[col].unique().tolist() if pd.notna(val)] ) for col in categorical_cols]\n",
    "\n",
    "# to robię by uniknąć data leakage (pewnie poprawię potem by ładniej wyglądało)\n",
    "stats = {col: X_train[col].median() for col in numeric_cols}\n",
    "stats.update({col: X_train[col].mode()[0] for col in categorical_cols})\n",
    "\n",
    "# tutaj gotowe dane do karmienia modelu\n",
    "X_train_preprocessed = preprocess(X_train,numeric_cols,categorical_cols_with_vals,scaler,stats)\n",
    "X_test_preprocessed = preprocess(X_test,numeric_cols,categorical_cols_with_vals,scaler,stats)\n",
    "X_subtest_preprocessed = preprocess(X_subtest,numeric_cols,categorical_cols_with_vals,scaler,stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20705b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.467155259234633\n"
     ]
    }
   ],
   "source": [
    "baseline = np.ones(len(y))*np.average(y)\n",
    "mse_baseline = metrics.mean_squared_error(y, baseline)\n",
    "\n",
    "clf = linear_model.LinearRegression()\n",
    "clf.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_preprocessed)\n",
    "mse_st = metrics.mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(mse_baseline / mse_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "743d1c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear (double split): MSE walidacja = 4274689367.6857\n",
      "Ridge: MSE walidacja = 4267546199.3754\n",
      "Lasso: MSE walidacja = 4274677094.3301\n",
      "kNN: MSE walidacja = 2893316010.1203\n",
      "ElasticNet: MSE walidacja = 5170330334.9276\n",
      "RandomForestRegressor: MSE walidacja = 2646255457.4766\n",
      "Najlepszy model: RandomForestRegressor\n",
      "1.7520247859594231\n",
      "\n",
      "=== Ewaluacja najlepszego modelu (test) ===\n",
      "MSE:   1859940305.68\n",
      "RMSE:  43127.03\n",
      "MAE:   7460.47\n",
      "R2:    0.7333\n",
      "MAPE:  83.80%\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Linear (double split)\": linear_model.LinearRegression(),\n",
    "    \"Ridge\": Seeded(linear_model.Ridge)(alpha=0.1),\n",
    "    \"Lasso\": Seeded(linear_model.Lasso)(alpha=0.01),\n",
    "    \"kNN\": KNeighborsRegressor(n_neighbors=50, weights=\"distance\"),\n",
    "    \"ElasticNet\": Seeded(linear_model.ElasticNet)(alpha=0.1, l1_ratio=0.5),\n",
    "    \"RandomForestRegressor\": Seeded(RandomForestRegressor)(n_estimators=100, max_depth=20)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_preprocessed, y_train)\n",
    "    y_val_pred = model.predict(X_subtest_preprocessed)\n",
    "    mse_val_best = metrics.mean_squared_error(y_subtest, y_val_pred)\n",
    "    results[name] = mse_val_best\n",
    "    print(f\"{name}: MSE walidacja = {mse_val_best:.4f}\")\n",
    "\n",
    "best_model_name = min(results, key=results.get)\n",
    "print(f\"Najlepszy model: {best_model_name}\")\n",
    "\n",
    "y_pred = models[best_model_name].predict(X_test_preprocessed)\n",
    "mse_val_best = metrics.mean_squared_error(y_test, y_pred)\n",
    "print(mse_st / mse_val_best)\n",
    "\n",
    "rmse = np.sqrt(mse_val_best)\n",
    "mae  = metrics.mean_absolute_error(y_test, y_pred)\n",
    "r2   = metrics.r2_score(y_test, y_pred)\n",
    "mape = metrics.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(\"\\n=== Ewaluacja najlepszego modelu (test) ===\")\n",
    "print(f\"MSE:   {mse_val_best:.2f}\")\n",
    "print(f\"RMSE:  {rmse:.2f}\")\n",
    "print(f\"MAE:   {mae:.2f}\")\n",
    "print(f\"R2:    {r2:.4f}\")\n",
    "print(f\"MAPE:  {mape*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5104344e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear (double split): MSE walidacja = 3499411842.5259\n",
      "Ridge: MSE walidacja = 3495426445.6761\n",
      "Lasso: MSE walidacja = 4213326995.7163\n",
      "kNN: MSE walidacja = 3940587746.8179\n",
      "ElasticNet: MSE walidacja = 4251126737.8177\n",
      "RandomForestRegressor: MSE walidacja = 2522608193.2408\n",
      "Najlepszy model (skala log.): RandomForestRegressor\n",
      "MSE test: 1.0314195197198421\n",
      "\n",
      "=== Ewaluacja najlepszego modelu (test) ===\n",
      "MSE:   1803282049.76\n",
      "RMSE:  42465.07\n",
      "MAE:   7276.36\n",
      "R2:    0.7414\n",
      "MAPE:  77.08%\n"
     ]
    }
   ],
   "source": [
    "### Log-ification of database\n",
    "\n",
    "results_log = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_preprocessed, np.log1p(y_train))\n",
    "    y_val_pred_log = model.predict(X_subtest_preprocessed)\n",
    "    y_val_pred = np.expm1(y_val_pred_log)\n",
    "    mse_val = metrics.mean_squared_error(y_subtest, y_val_pred)\n",
    "    results_log[name] = mse_val\n",
    "    print(f\"{name}: MSE walidacja = {mse_val:.4f}\")\n",
    "\n",
    "best_model = models[best_model_name]\n",
    "print(f\"Najlepszy model (skala log.): {best_model_name}\")\n",
    "best_model.fit(X_train_preprocessed, np.log1p(y_train))\n",
    "\n",
    "y_pred_log = best_model.predict(X_test_preprocessed)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "mse_log = metrics.mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE test:\", mse_val_best / mse_log)\n",
    "\n",
    "rmse = np.sqrt(mse_log)\n",
    "mae  = metrics.mean_absolute_error(y_test, y_pred)\n",
    "r2   = metrics.r2_score(y_test, y_pred)\n",
    "mape = metrics.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(\"\\n=== Ewaluacja najlepszego modelu (test) ===\")\n",
    "print(f\"MSE:   {mse_log:.2f}\")\n",
    "print(f\"RMSE:  {rmse:.2f}\")\n",
    "print(f\"MAE:   {mae:.2f}\")\n",
    "print(f\"R2:    {r2:.4f}\")\n",
    "print(f\"MAPE:  {mape*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0464d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 113920 entries, 0 to 118381\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   price       113920 non-null  float64\n",
      " 1   make        113920 non-null  object \n",
      " 2   car_age     113920 non-null  float64\n",
      " 3   mileage_km  113920 non-null  float64\n",
      " 4   power_kw    113920 non-null  float64\n",
      " 5   gears       73105 non-null   float64\n",
      " 6   cylinders   91936 non-null   float64\n",
      " 7   is_new      113920 non-null  bool   \n",
      "dtypes: bool(1), float64(6), object(1)\n",
      "memory usage: 7.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (df.info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
